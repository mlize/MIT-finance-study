{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas_datareader import data, wb"
   ]
  },
  {
   "source": [
    "# Gather and clean the data : "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stocks we'll use for this analysis\n",
    "# Stock_list = ['GE','BAC','JDSU','XOM','^GSPC'] ( Note that the stock JDSU is not working)\n",
    "\n",
    "Stock_list = ['GE','BAC','XOM']\n",
    "\n",
    "# Set up End and Start times for data grab\n",
    "\n",
    "startDate = '2000-01-01'\n",
    "endDate = '2013-05-31'\n",
    "\n",
    "# #For loop for grabing yahoo finance data and setting as a dataframe\n",
    "# panel_data = data.DataReader('INPX', 'yahoo', start, end)\n",
    "\n",
    "SNP = data.DataReader('^GSPC','yahoo',startDate,endDate)\n",
    "for stock in Stock_list:   \n",
    "    # Set DataFrame as the Stock Ticker\n",
    "    globals()[stock] = data.DataReader(stock,'yahoo',startDate,endDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the close price for all the stocks:\n",
    "stocksClose =pd.concat([GE['Adj Close'].rename('GE'),BAC['Adj Close'].rename('BAC'),XOM['Adj Close'].rename('XOM'),SNP['Adj Close'].rename('S&P')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Federal Reserve Economic Data (FRED) from the St. Louis Federal Reserve\n",
    "#       \n",
    "#\n",
    "#             Returns historical data for any symbol at the website\n",
    "#               http://research.stlouisfed.org/fred2/\n",
    "#\n",
    "# Series name | Description\n",
    "# \n",
    "# DGS3MO      | 3-Month Treasury, constant maturity rate\n",
    "# DGS1        | 1-Year Treasury, constant maturity rate\n",
    "# DGS5        | 5-Year Treasury, constant maturity rate\n",
    "# DGS10       | 10-Year Treasury, constant maturity rate\n",
    "#\n",
    "# DAAA        | Moody's Seasoned Aaa Corporate Bond Yield \n",
    "# DBAA        | Moody's Seasoned Baa Corporate Bond Yield \n",
    "#\n",
    "# DCOILWTICO  | Crude Oil Prices: West Text Intermediate (WTI) - Cushing, Oklahoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fredList = ['DGS3MO','DGS1','DGS5','DGS10','DAAA','DBAA','DCOILWTICO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fredData = data.DataReader(fredList,'fred',startDate,endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The join= 'inner' options takes the index intersection of all data frames. The join ='Outer' ( default) takes the union.\n",
    "allData =pd.concat([fredData,stocksClose],axis=1,join='inner').rename_axis('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.to_csv('rawData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DGS3MO        24\n",
       "DGS1          24\n",
       "DGS5          24\n",
       "DGS10         24\n",
       "DAAA          24\n",
       "DBAA          24\n",
       "DCOILWTICO    14\n",
       "GE             0\n",
       "BAC            0\n",
       "XOM            0\n",
       "S&P            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "############################################################################################################################################################################# DATA CLEANING:\n",
    "###########################################################################################################################################################################\n",
    "\n",
    "# Count the number of NaN values: \n",
    "allData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to fill the missing value with the previews non NanN value, i.e forward fill. \n",
    "cleanData = allData.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DGS3MO        0\n",
       "DGS1          0\n",
       "DGS5          0\n",
       "DGS10         0\n",
       "DAAA          0\n",
       "DBAA          0\n",
       "DCOILWTICO    1\n",
       "GE            0\n",
       "BAC           0\n",
       "XOM           0\n",
       "S&P           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "# The only missing values is the first entry in DGS3MO\n",
    "cleanData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean data: \n",
    "cleanData.to_csv('cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}